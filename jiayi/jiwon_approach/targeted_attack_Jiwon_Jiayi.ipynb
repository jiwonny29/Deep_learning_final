{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eJRMwfA-_aX7","executionInfo":{"status":"ok","timestamp":1733254086523,"user_tz":300,"elapsed":19309,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"4551712f-f5ea-4380-9c23-d401e2a27a6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab\\ Notebooks/Deep_learning_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QYlRMyFD_dxe","executionInfo":{"status":"ok","timestamp":1733254087008,"user_tz":300,"elapsed":488,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"f592e5fa-25fc-4b4d-8b23-0bc4469cd342"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Deep_learning_final\n"]}]},{"cell_type":"markdown","source":["Table by animal\n","\n","| **Patch Size** | **Cat**   | **Deer**  | **Dog**   | **Frog**  |\n","|----------------|-----------|-----------|-----------|-----------|\n","| **Size 3**     | 10.25%    | 9.41%     | 11.20%    | 9.37%     |\n","| **Size 5**     | 10.12%    | 10.23%    | 10.66%    | 9.16%     |\n","| **Size 7**     | 9.88%     | 10.49%    | 10.79%    | 9.86%     |\n","| **Size 16**    | 9.52%     | 12.13%    | 13.67%    | 9.35%     |\n","\n","Table by size\n","\n","| **Target Class** | **Size 3** | **Size 5** | **Size 7** | **Size 16** |\n","|------------------|------------|------------|------------|-------------|\n","| **Cat**          | 10.25%     | 10.12%     | 9.88%      | 9.52%       |\n","| **Deer**         | 9.41%      | 10.23%     | 10.49%     | 12.13%      |\n","| **Dog**          | 11.20%     | 10.66%     | 10.79%     | 13.67%      |\n","| **Frog**         | 9.37%      | 9.16%      | 9.86%      | 9.35%       |"],"metadata":{"id":"96YhW1UKzVfA"}},{"cell_type":"code","source":["# Function to create a random patch\n","def create_patch(patch_size=(3, 3)):\n","    patch = torch.randn(3, *patch_size, requires_grad=True, device=device)\n","    return patch\n","\n","# Function to apply the patch to images\n","def place_patch(img, patch):\n","    batch_size, _, h, w = img.size()\n","    ph, pw = patch.size(1), patch.size(2)\n","    for i in range(batch_size):\n","        x_offset = torch.randint(0, h - ph + 1, (1,)).item()\n","        y_offset = torch.randint(0, w - pw + 1, (1,)).item()\n","        img[i, :, x_offset:x_offset+ph, y_offset:y_offset+pw] = patch\n","    return img\n","\n","# Training function for adversarial patch\n","def patch_training_step(model, patch, target_class=None, dataloader=None, optimizer=None, criterion=None):\n","    model.train()\n","    total_loss = 0\n","    for images, _ in dataloader:\n","        images = images.to(device)\n","        optimizer.zero_grad()\n","        patched_images = place_patch(images, patch)\n","        outputs = model(patched_images)\n","        if target_class is not None:\n","            labels = torch.full((images.size(0),), target_class, dtype=torch.long, device=device)\n","        else:\n","            labels = torch.randint(0, 10, (images.size(0),), device=device)  # Random class for untargeted attack\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","    return total_loss / len(dataloader)\n","\n","# Function to train the adversarial patch\n","def train_adversarial_patch(model, patch, target_class=None, num_epochs=10):\n","    patch_optimizer = optim.Adam([patch], lr=0.01)\n","    criterion = nn.CrossEntropyLoss()\n","    for epoch in range(num_epochs):\n","        loss = patch_training_step(model, patch, target_class, trainloader, patch_optimizer, criterion)\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}\")\n","\n","# Function to evaluate the success rate of the adversarial patch\n","def evaluate_patch_success_rate(model, patch, dataloader, target_class=None):\n","    model.eval()\n","    successful_attacks = 0\n","    total_samples = 0\n","    with torch.no_grad():\n","        for images, labels in dataloader:\n","            images, labels = images.to(device), labels.to(device)\n","            patched_images = place_patch(images.clone(), patch)\n","            outputs = model(patched_images)\n","            _, predicted = outputs.max(1)\n","\n","            # Count successful targeted attacks (where prediction matches the target class)\n","            if target_class is not None:\n","                successful_attacks += (predicted == target_class).sum().item()\n","            total_samples += labels.size(0)\n","\n","    success_rate = 100 * successful_attacks / total_samples\n","    print(f\"Targeted Attack Success Rate: {success_rate:.2f}%\")\n","    return success_rate\n","\n","# Function to visualize the patch\n","def visualize_patch(patch):\n","    patch = patch.detach().cpu().numpy()\n","    patch = np.clip((patch - patch.min()) / (patch.max() - patch.min()), 0, 1)\n","\n","    plt.figure(figsize=(2, 2))\n","    plt.imshow(np.transpose(patch, (1, 2, 0)))  # [C, H, W] -> [H, W, C]\n","    plt.title(\"Adversarial Patch\")\n","    plt.axis('off')\n","    plt.show()\n","\n","# Function to visualize misclassified patched images\n","def visualize_misclassified_patched_images(model, patch, dataloader, classes, target_class, num_examples=5):\n","    model.eval()\n","    examples_shown = 0\n","    for images, labels in dataloader:\n","        images, labels = images.to(device), labels.to(device)\n","        patched_images = place_patch(images.clone(), patch)\n","        with torch.no_grad():\n","            original_preds = model(images).argmax(dim=1)\n","            patched_preds = model(patched_images).argmax(dim=1)\n","        for i in range(images.size(0)):\n","            if patched_preds[i] == target_class:  # Targeted attack\n","                original_image = (images[i].cpu().detach().numpy().transpose(1, 2, 0) * 0.5) + 0.5\n","                patched_image = (patched_images[i].cpu().detach().numpy().transpose(1, 2, 0) * 0.5) + 0.5\n","\n","                fig, axes = plt.subplots(1, 2, figsize=(4, 4))\n","                axes[0].imshow(np.clip(original_image, 0, 1))\n","                axes[0].set_title(f\"Original Image\\nTrue Label: {classes[labels[i].item()]}\\nPredicted: {classes[original_preds[i].item()]}\")\n","\n","                axes[1].imshow(np.clip(patched_image, 0, 1))\n","                axes[1].set_title(f\"Image with Adversarial Patch\\nTrue Label: {classes[labels[i].item()]}\\nPredicted: {classes[patched_preds[i].item()]}\")\n","\n","                plt.show()\n","                examples_shown += 1\n","                if examples_shown >= num_examples:\n","                    return"],"metadata":{"id":"-UCYcB4CEsYG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJm4nPLpEm82","executionInfo":{"status":"ok","timestamp":1733254126052,"user_tz":300,"elapsed":28088,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"dbf95b56-5788-4ca5-f7d5-2b03d8e7a5db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Set up device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load and preprocess the CIFAR-10 dataset\n","transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"]},{"cell_type":"code","source":["from torchvision import models\n","num_classes =10\n","\n","# CIFAR-10 class names\n","classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","# Targeted classes (plane, car, bird)\n","target_classes = [3,4,5,6]  # Corresponding to 'cat', 'deer', 'dog', 'frog'\n","\n","# Different patch sizes\n","patch_sizes = [(3, 3), (5, 5), (7, 7), (16, 16)]\n","\n","#load resnet\n","model = models.resnet18(pretrained=False)\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","model.load_state_dict(torch.load(\"cifar_resnet18_pretrained.pth\"))\n","model = model.to(device)\n","\n","# Train and evaluate patches for each target class\n","for target_class in target_classes:\n","    for patch_size in patch_sizes:\n","        print(f\"\\nTraining for patch size: {patch_size} with target class: {classes[target_class]}\")\n","        patch = create_patch(patch_size)\n","        train_adversarial_patch(model, patch, target_class=target_class, num_epochs=20)\n","\n","        # Save the patch\n","        torch.save(patch, f'adversarial_patch_{patch_size[0]}x{patch_size[1]}_target_{target_class}.pth')\n","\n","        # Visualize the patch\n","        print(f\"Visualizing patch of size {patch_size} for target class {classes[target_class]}\")\n","        visualize_patch(patch)\n","\n","        # Evaluate attack success rate\n","        evaluate_patch_success_rate(model, patch, testloader, target_class=target_class)\n","\n","        # Visualize misclassified examples with the adversarial patch\n","        visualize_misclassified_patched_images(model, patch, testloader, classes, target_class, num_examples=5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"123GPOxIYIjJVWRkY2NwQeKEPeot_FSyf"},"id":"jK7eyPWvEvwy","executionInfo":{"status":"ok","timestamp":1733259029838,"user_tz":300,"elapsed":4880335,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"e7c18850-cc7f-4bef-e94c-299a7286aa65"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}