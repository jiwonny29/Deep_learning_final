{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_D4tIbWI-om","executionInfo":{"status":"ok","timestamp":1733358992980,"user_tz":300,"elapsed":1470,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"7fe592a6-54d2-4676-dea1-6e9eb30ace41"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab\\ Notebooks/Deep_learning_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MiSFvSQVJFT7","executionInfo":{"status":"ok","timestamp":1733358997034,"user_tz":300,"elapsed":296,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"0b58954f-e789-491b-b7d9-a4ab8c05e037"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Deep_learning_final\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","# Set up GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load and preprocess the CIFAR-10 dataset\n","transform = transforms.Compose(\n","    [\n","        # transforms.RandomHorizontalFlip(),\n","        # transforms.RandomCrop(32, padding=4),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","    ]\n",")\n","\n","trainset = torchvision.datasets.CIFAR10(\n","    root=\"./data\", train=True, download=True, transform=transform\n",")\n","trainloader = torch.utils.data.DataLoader(\n","    trainset, batch_size=128, shuffle=True, num_workers=2\n",")\n","\n","testset = torchvision.datasets.CIFAR10(\n","    root=\"./data\", train=False, download=True, transform=transform\n",")\n","testloader = torch.utils.data.DataLoader(\n","    testset, batch_size=100, shuffle=False, num_workers=2\n",")"],"metadata":{"id":"ke-URZBaxrRm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733359005079,"user_tz":300,"elapsed":2783,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"8a9671a4-6287-4b6d-936b-49e4a7ea5f7d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["import torchvision.models as models\n","\n","def train(model, trainloader, criterion, optimizer, num_epochs=10):\n","    model.train()\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        for inputs, labels in trainloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        scheduler.step()\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n","\n","def evaluate(model, testloader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in testloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    print(f\"Accuracy: {100 * correct / total:.2f}%\")"],"metadata":{"id":"BDiW60CRP5-H","executionInfo":{"status":"ok","timestamp":1733359021475,"user_tz":300,"elapsed":292,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Load pre-trained ResNet-18 model\n","model = models.resnet18(pretrained=True)\n","\n","# Modify the first convolutional layer\n","model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","\n","# Remove the first max pooling layer\n","model.maxpool = nn.Identity()\n","\n","# Modify the final layer for CIFAR-10\n","num_classes = 10\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n","\n","# Train the model\n","train(model, trainloader, criterion, optimizer, num_epochs=20)\n","\n","# Evaluate the model\n","evaluate(model, testloader)\n","\n","# Save the model\"cifar_resnet18_pretrained.pth\"\n","torch.save(model.state_dict(), \"lin_cifar_resnet18_pretrained.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tyduhdIjxrQD","outputId":"8c5c06ce-65c9-4fce-8e92-df17cf773491","executionInfo":{"status":"ok","timestamp":1733240812264,"user_tz":300,"elapsed":497458,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 170MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Loss: 1.0527\n","Epoch [2/20], Loss: 0.7189\n","Epoch [3/20], Loss: 0.6249\n","Epoch [4/20], Loss: 0.5742\n","Epoch [5/20], Loss: 0.5234\n","Epoch [6/20], Loss: 0.4977\n","Epoch [7/20], Loss: 0.4690\n","Epoch [8/20], Loss: 0.4459\n","Epoch [9/20], Loss: 0.4284\n","Epoch [10/20], Loss: 0.4164\n","Epoch [11/20], Loss: 0.4023\n","Epoch [12/20], Loss: 0.3865\n","Epoch [13/20], Loss: 0.3725\n","Epoch [14/20], Loss: 0.3693\n","Epoch [15/20], Loss: 0.3595\n","Epoch [16/20], Loss: 0.3478\n","Epoch [17/20], Loss: 0.3402\n","Epoch [18/20], Loss: 0.3382\n","Epoch [19/20], Loss: 0.3243\n","Epoch [20/20], Loss: 0.3201\n","Accuracy: 82.19%\n"]}]},{"cell_type":"code","source":["num_classes = 10\n","\n","# Load DenseNet\n","densenet = models.densenet121(pretrained=True)\n","densenet.classifier = nn.Linear(densenet.classifier.in_features, num_classes)\n","densenet = densenet.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer_densenet = optim.Adam(densenet.parameters(), lr=0.001, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer_densenet, step_size=30, gamma=0.1)\n","trainloader_densenet = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n","\n","# Use the same train and evaluate functions as before\n","train(densenet, trainloader_densenet, criterion, optimizer_densenet, num_epochs=20)\n","evaluate(densenet, testloader)\n","torch.save(densenet.state_dict(), \"lin_cifar_densenet_pretrained.pth\")"],"metadata":{"id":"p_c4NnA0fFi7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733360473170,"user_tz":300,"elapsed":1328197,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"7e105910-01ab-4b6e-f3af-280c2d575723"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Loss: 0.8696\n","Epoch [2/20], Loss: 0.5532\n","Epoch [3/20], Loss: 0.4479\n","Epoch [4/20], Loss: 0.3820\n","Epoch [5/20], Loss: 0.3243\n","Epoch [6/20], Loss: 0.2857\n","Epoch [7/20], Loss: 0.2559\n","Epoch [8/20], Loss: 0.2231\n","Epoch [9/20], Loss: 0.2002\n","Epoch [10/20], Loss: 0.1869\n","Epoch [11/20], Loss: 0.1692\n","Epoch [12/20], Loss: 0.1655\n","Epoch [13/20], Loss: 0.1494\n","Epoch [14/20], Loss: 0.1439\n","Epoch [15/20], Loss: 0.1345\n","Epoch [16/20], Loss: 0.1297\n","Epoch [17/20], Loss: 0.1298\n","Epoch [18/20], Loss: 0.1181\n","Epoch [19/20], Loss: 0.1249\n","Epoch [20/20], Loss: 0.1149\n","Accuracy: 83.66%\n"]}]},{"cell_type":"code","source":["num_classes = 10\n","\n","# Load VGG\n","vgg = models.vgg16(pretrained=True)\n","vgg.classifier[6] = nn.Linear(vgg.classifier[6].in_features, num_classes)\n","vgg = vgg.to(device)\n","\n","trainloader_VGG = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer_VGG = optim.SGD(vgg.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer_VGG, step_size=30, gamma=0.1)\n","\n","# Use the same train and evaluate functions as before\n","train(vgg, trainloader_VGG, criterion, optimizer_VGG, num_epochs=20)\n","evaluate(vgg, testloader)\n","torch.save(vgg.state_dict(), \"lin_cifar_vgg_pretrained.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FEQiRyZxR1r1","executionInfo":{"status":"ok","timestamp":1733361547070,"user_tz":300,"elapsed":1073903,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"5b6dba95-714c-4372-e59f-2b0bca2f1d7b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:06<00:00, 85.1MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Loss: 0.7392\n","Epoch [2/20], Loss: 0.4212\n","Epoch [3/20], Loss: 0.3036\n","Epoch [4/20], Loss: 0.2192\n","Epoch [5/20], Loss: 0.1521\n","Epoch [6/20], Loss: 0.1073\n","Epoch [7/20], Loss: 0.0836\n","Epoch [8/20], Loss: 0.0531\n","Epoch [9/20], Loss: 0.0457\n","Epoch [10/20], Loss: 0.0360\n","Epoch [11/20], Loss: 0.0238\n","Epoch [12/20], Loss: 0.0225\n","Epoch [13/20], Loss: 0.0215\n","Epoch [14/20], Loss: 0.0141\n","Epoch [15/20], Loss: 0.0184\n","Epoch [16/20], Loss: 0.0217\n","Epoch [17/20], Loss: 0.0068\n","Epoch [18/20], Loss: 0.0128\n","Epoch [19/20], Loss: 0.0076\n","Epoch [20/20], Loss: 0.0041\n","Accuracy: 88.70%\n"]}]},{"cell_type":"code","source":["from torchvision import models\n","\n","# Number of classes for CIFAR-10\n","num_classes = 10\n","\n","# Define the criterion and scheduler\n","criterion = nn.CrossEntropyLoss()\n","\n","# Load Pretrained MobileNetV2\n","mobilenet = models.mobilenet_v2(pretrained=True)\n","\n","# Modify the classifier to fit CIFAR-10 (num_classes = 10)\n","mobilenet.classifier[1] = nn.Linear(mobilenet.classifier[1].in_features, num_classes)\n","mobilenet = mobilenet.to(device)\n","\n","# Define the optimizer\n","optimizer_mobilenet = optim.Adam(mobilenet.parameters(), lr=0.001, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer_mobilenet, step_size=30, gamma=0.1)\n","# Set up the DataLoader (use your existing trainset and testloader)\n","trainloader_mobilenet = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n","\n","# Train the model (use your train function)\n","train(mobilenet, trainloader_mobilenet, criterion, optimizer_mobilenet, num_epochs=20)\n","\n","# Evaluate the model (use your evaluate function)\n","evaluate(mobilenet, testloader)\n","\n","# Save the model weights\n","torch.save(mobilenet.state_dict(), \"lin_cifar_mobilenet_pretrained.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HQlNAPjubVF2","executionInfo":{"status":"ok","timestamp":1733362182190,"user_tz":300,"elapsed":635124,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"33d57c5a-349e-4996-8a95-3a52208961e8"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n","100%|██████████| 13.6M/13.6M [00:00<00:00, 167MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Loss: 0.9624\n","Epoch [2/20], Loss: 0.6805\n","Epoch [3/20], Loss: 0.5914\n","Epoch [4/20], Loss: 0.5584\n","Epoch [5/20], Loss: 0.4963\n","Epoch [6/20], Loss: 0.4621\n","Epoch [7/20], Loss: 0.4284\n","Epoch [8/20], Loss: 0.4290\n","Epoch [9/20], Loss: 0.3892\n","Epoch [10/20], Loss: 0.3639\n","Epoch [11/20], Loss: 0.3404\n","Epoch [12/20], Loss: 0.3323\n","Epoch [13/20], Loss: 0.3152\n","Epoch [14/20], Loss: 0.3039\n","Epoch [15/20], Loss: 0.2752\n","Epoch [16/20], Loss: 0.2659\n","Epoch [17/20], Loss: 0.2619\n","Epoch [18/20], Loss: 0.2541\n","Epoch [19/20], Loss: 0.2410\n","Epoch [20/20], Loss: 0.2318\n","Accuracy: 81.23%\n"]}]},{"cell_type":"code","source":["#efficient net\n","from torchvision.models import efficientnet_b0\n","\n","# Load pretrained EfficientNet model\n","efficientnet = efficientnet_b0(pretrained=True)\n","efficientnet.classifier[1] = nn.Linear(efficientnet.classifier[1].in_features, 10)  # Adjust for CIFAR-10\n","efficientnet = efficientnet.to(device)\n","\n","# Optimizer and scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(efficientnet.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n","\n","# Train and evaluate\n","train(efficientnet, trainloader, criterion, optimizer, num_epochs=20)\n","evaluate(efficientnet, testloader)\n","\n","#save\n","torch.save(efficientnet.state_dict(), \"lin_cifar_efficientnet_pretrained.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7dF0a6J6dmpX","executionInfo":{"status":"ok","timestamp":1733362695322,"user_tz":300,"elapsed":513138,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"59597ff0-1a44-401d-a20a-415e49d416c4"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n","100%|██████████| 20.5M/20.5M [00:00<00:00, 120MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Loss: 1.8316\n","Epoch [2/20], Loss: 1.2686\n","Epoch [3/20], Loss: 1.0499\n","Epoch [4/20], Loss: 0.9244\n","Epoch [5/20], Loss: 0.8310\n","Epoch [6/20], Loss: 0.7580\n","Epoch [7/20], Loss: 0.6997\n","Epoch [8/20], Loss: 0.6508\n","Epoch [9/20], Loss: 0.6126\n","Epoch [10/20], Loss: 0.5772\n","Epoch [11/20], Loss: 0.5496\n","Epoch [12/20], Loss: 0.5225\n","Epoch [13/20], Loss: 0.4945\n","Epoch [14/20], Loss: 0.4739\n","Epoch [15/20], Loss: 0.4522\n","Epoch [16/20], Loss: 0.4341\n","Epoch [17/20], Loss: 0.4163\n","Epoch [18/20], Loss: 0.3982\n","Epoch [19/20], Loss: 0.3861\n","Epoch [20/20], Loss: 0.3714\n","Accuracy: 79.59%\n"]}]},{"cell_type":"code","source":["import torch\n","from torchvision import models\n","# Define the model (same architecture as when you saved it)\n","num_classes = 10\n","\n","#load resnet\n","resnet = models.resnet18(pretrained=False)\n","resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\n","resnet.load_state_dict(torch.load(\"lin_cifar_resnet18_pretrained.pth\"))\n","resnet = resnet.to(device)\n","\n","#load densenet\n","densenet = models.densenet121(pretrained=False)  # Don't load the pre-trained weights initially\n","densenet.classifier = nn.Linear(densenet.classifier.in_features, num_classes)\n","densenet.load_state_dict(torch.load(\"lin_cifar_densenet_pretrained.pth\"))\n","densenet = densenet.to(device)\n","\n","#load vgg\n","vgg = models.vgg16(pretrained=False)\n","vgg.classifier[6] = nn.Linear(vgg.classifier[6].in_features, num_classes)\n","vgg.load_state_dict(torch.load(\"lin_cifar_vgg_pretrained.pth\"))\n","vgg = vgg.to(device)\n","\n","#load mobilenet\n","mobilenet = models.mobilenet_v2(pretrained=False)\n","mobilenet.classifier[1] = nn.Linear(mobilenet.classifier[1].in_features, num_classes)\n","mobilenet.load_state_dict(torch.load(\"lin_cifar_mobilenet_pretrained.pth\"))\n","mobilenet = mobilenet.to(device)\n","\n","#load efficientnet\n","efficientnet = efficientnet_b0(pretrained=False)\n","efficientnet.classifier[1] = nn.Linear(efficientnet.classifier[1].in_features, num_classes)\n","efficientnet.load_state_dict(torch.load(\"lin_cifar_efficientnet_pretrained.pth\"))\n","efficientnet = efficientnet.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5jdyXMinfZpk","executionInfo":{"status":"ok","timestamp":1733247860792,"user_tz":300,"elapsed":505,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"3d48bef3-61a7-4484-cfc3-804d3e86c542"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","<ipython-input-39-731b023d77e9>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  densenet_2.load_state_dict(torch.load(\"cifar_densenet_pretrained.pth\"))\n"]}]},{"cell_type":"code","source":["def evaluate_transferability(model, patch, dataloader):\n","    model.eval()\n","    untargeted_success = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in dataloader:\n","            images, labels = images.to(device), labels.to(device)\n","            patched_images = place_patch(images.clone(), patch)\n","            outputs = model(patched_images)\n","            _, predicted = outputs.max(1)\n","            untargeted_success += (predicted != labels).sum().item()\n","            total += labels.size(0)\n","    return 100 * untargeted_success / total\n","\n","# Load the patch\n","patch = torch.load('adversarial_patch_5_5.pth')\n","\n","# Evaluate transferability\n","resnet_rate = evaluate_transferability(model, patch, testloader)\n","print(f\"Untargeted Attack Success Rate on ResNet: {resnet_rate:.2f}%\")\n","\n","densenet_rate = evaluate_transferability(densenet, patch, testloader)\n","print(f\"Untargeted Attack Success Rate on DenseNet: {densenet_rate:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D55zjiobMhXo","executionInfo":{"status":"ok","timestamp":1733243009584,"user_tz":300,"elapsed":10614,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"cc5c8762-1115-419a-ebb2-96762dc8a4ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-27-ca80d6cdfda8>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  patch = torch.load('adversarial_patch_5_5.pth')\n"]},{"output_type":"stream","name":"stdout","text":["Untargeted Attack Success Rate on ResNet: 49.41%\n","Untargeted Attack Success Rate on DenseNet: 89.29%\n"]}]},{"cell_type":"code","source":["# Load the patch\n","patch = torch.load('adversarial_patch_5_5.pth')\n","\n","# Evaluate transferability\n","resnet_rate = evaluate_transferability(model, patch, testloader)\n","print(f\"Untargeted Attack Success Rate on ResNet: {resnet_rate:.2f}%\")\n","\n","densenet_rate = evaluate_transferability(densenet, patch, testloader)\n","print(f\"Untargeted Attack Success Rate on DenseNet: {densenet_rate:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ado2hXPhbzPv","executionInfo":{"status":"ok","timestamp":1733245086297,"user_tz":300,"elapsed":11627,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"610d655f-6539-4da1-9413-e8bc34668a07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-30-d27fc4e47b23>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  patch = torch.load('adversarial_patch_5_5.pth')\n"]},{"output_type":"stream","name":"stdout","text":["Untargeted Attack Success Rate on ResNet: 48.99%\n","Untargeted Attack Success Rate on DenseNet: 75.71%\n"]}]},{"cell_type":"code","source":["vgg_rate = evaluate_transferability(vgg, patch, testloader)\n","print(f\"Untargeted Attack Success Rate on VGG: {vgg_rate:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-8KRFBXR50r","executionInfo":{"status":"ok","timestamp":1733246206139,"user_tz":300,"elapsed":7173,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"aba60954-ceed-4f54-aef6-6ee1b926efd4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Untargeted Attack Success Rate on VGG: 76.72%\n"]}]},{"cell_type":"code","source":["#mobilenet\n","mobilenet_rate = evaluate_transferability(mobilenet, patch, testloader)\n","print(f\"Untargeted Attack Success Rate on MobileNet: {mobilenet_rate:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ePviJWoMb6FK","executionInfo":{"status":"ok","timestamp":1733246969991,"user_tz":300,"elapsed":4585,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"c19156c1-e31a-48f3-8cd7-223dabf23bf8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Untargeted Attack Success Rate on MobileNet: 54.89%\n"]}]},{"cell_type":"code","source":["efficientnet_rate = evaluate_transferability(efficientnet, patch, testloader)\n","print(f\"Untargeted Attack Success Rate on EfficientNet: {efficientnet_rate:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eAx_DAzwdxt7","executionInfo":{"status":"ok","timestamp":1733247709650,"user_tz":300,"elapsed":6159,"user":{"displayName":"Jiayi Zhou","userId":"07115367295685510510"}},"outputId":"b79515f5-905b-46be-8198-e729e6d9696e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Untargeted Attack Success Rate on EfficientNet: 61.53%\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torchvision.models import vit_b_16\n","\n","# Device configuration\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define number of classes\n","num_classes = 10\n","\n","# Define Loss Function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Data Preprocessing\n","transform = transforms.Compose([\n","    transforms.Resize(224),  # Vision Transformer requires 224x224 input\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize to [-1, 1]\n","])\n","\n","trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n","\n","testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n","\n","# Load Pretrained Vision Transformer\n","vit = vit_b_16(pretrained=True)\n","vit.heads = nn.Linear(vit.heads.in_features, num_classes)  # Modify final layer for CIFAR-10\n","vit = vit.to(device)\n","\n","# Define Optimizer and Scheduler\n","optimizer_vit = optim.SGD(vit.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n","\n","# Training Function\n","def train(model, trainloader, criterion, optimizer, num_epochs):\n","    model.train()\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        for inputs, labels in trainloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        scheduler.step()\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n","\n","# Evaluation Function\n","def evaluate(model, testloader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in testloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n","\n","# Train and Evaluate ViT\n","train(vit, trainloader, criterion, optimizer_vit, num_epochs=20)\n","evaluate(vit, testloader)\n","\n","# Save the Trained Model\n","torch.save(vit.state_dict(), \"cifar_vit_pretrained.pth\")"],"metadata":{"id":"5QvPEnK4X1PN"},"execution_count":null,"outputs":[]}]}