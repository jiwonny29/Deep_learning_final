{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning - Targeted ASR (%) by Model, Target Class, and Patch Size\n",
        "\n",
        "| Target Class | Transfer to Model | Patch Size (3, 3) | Patch Size (5, 5) | Patch Size (7, 7) | Patch Size (16, 16) |\n",
        "|--------------|-------------------|-------------------|-------------------|-------------------|---------------------|\n",
        "| **airplane (0)**| **densenet**      | 14.12              | 9.85              | 17.74              | 6.68                |\n",
        "|              | **vgg**           | 30.63              | 36.81              | 45.39              | 0.00                |\n",
        "|              | **mobilenet**     | 12.44             | 14.28             | 23.30             | 95.10                |\n",
        "|              | **efficientnet**  | 10.26              | 10.00             | 18.51             | 3.28                |\n",
        "| **automobile (1)** | **densenet**      | 8.90              | 10.14              | 12.99             | 39.19               |\n",
        "|              | **vgg**           | 5.97             | 10.99              | 9.63              | 49.32                |\n",
        "|              | **mobilenet**     | 12.90              | 14.54              | 14.52              | 11.41               |\n",
        "|              | **efficientnet**  | 9.95              | 8.99              | 8.16              | 2.26                |\n",
        "| **bird (2)**| **densenet**      | 31.64              | 60.79              | 77.69              | 64.19               |\n",
        "|              | **vgg**           | 41.94              | 29.29              | 28.99             | 1.42               |\n",
        "|              | **mobilenet**     | 13.83             | 41.64             | 43.61              | 7.36                |\n",
        "|              | **efficientnet**  | 13.75             | 15.37             | 17.39             | 27.60               |"
      ],
      "metadata": {
        "id": "A4exuiONl6Ew"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEATjvH9UL45",
        "outputId": "7ac7e9cd-7ae3-4c4f-b95d-bc7967343ebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Wt7KbtRUMkP",
        "outputId": "d24ff41c-447a-426b-87ee-b1491e3a6495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/jiwon_patch\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/jiwon_patch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NJQHC1npUHmL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torchvision.models import efficientnet_b0\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48SZKJAtUHmN",
        "outputId": "ca786bca-3b81-48b9-e51d-6645578f7797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: CUDA\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU: CUDA\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EwhbZZCUHmO",
        "outputId": "539dcd72-fd04-4de3-afab-fcfa5e54c96c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6DFQeSBFUHmO"
      },
      "outputs": [],
      "source": [
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOsF9EIpU-Gd",
        "outputId": "b96ac245-634d-4131-cbaf-8d3e865be2c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-7-ee4ae7c7d18f>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  densenet.load_state_dict(torch.load(\"transfer_models/cifar_densenet_pretrained.pth\"))\n",
            "<ipython-input-7-ee4ae7c7d18f>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  vgg.load_state_dict(torch.load(\"transfer_models/cifar_vgg_pretrained.pth\"))\n",
            "<ipython-input-7-ee4ae7c7d18f>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  mobilenet.load_state_dict(torch.load(\"transfer_models/cifar_mobilenet_pretrained.pth\"))\n",
            "<ipython-input-7-ee4ae7c7d18f>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  torch.load(\"transfer_models/cifar_efficientnet_pretrained.pth\")\n"
          ]
        }
      ],
      "source": [
        "# load densenet\n",
        "densenet = models.densenet121(\n",
        "    pretrained=False\n",
        ")  # Don't load the pre-trained weights initially\n",
        "densenet.classifier = nn.Linear(densenet.classifier.in_features, num_classes)\n",
        "densenet.load_state_dict(torch.load(\"transfer_models/cifar_densenet_pretrained.pth\"))\n",
        "densenet = densenet.to(device)\n",
        "\n",
        "# load vgg\n",
        "vgg = models.vgg16(pretrained=False)\n",
        "vgg.classifier[6] = nn.Linear(vgg.classifier[6].in_features, num_classes)\n",
        "vgg.load_state_dict(torch.load(\"transfer_models/cifar_vgg_pretrained.pth\"))\n",
        "vgg = vgg.to(device)\n",
        "\n",
        "# load mobilenet\n",
        "mobilenet = models.mobilenet_v2(pretrained=False)\n",
        "mobilenet.classifier[1] = nn.Linear(mobilenet.classifier[1].in_features, num_classes)\n",
        "mobilenet.load_state_dict(torch.load(\"transfer_models/cifar_mobilenet_pretrained.pth\"))\n",
        "mobilenet = mobilenet.to(device)\n",
        "\n",
        "# load efficientnet\n",
        "efficientnet = efficientnet_b0(pretrained=False)\n",
        "efficientnet.classifier[1] = nn.Linear(\n",
        "    efficientnet.classifier[1].in_features, num_classes\n",
        ")\n",
        "efficientnet.load_state_dict(\n",
        "    torch.load(\"transfer_models/cifar_efficientnet_pretrained.pth\")\n",
        ")\n",
        "efficientnet = efficientnet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yE8CcA0_VaAY"
      },
      "outputs": [],
      "source": [
        "transfer_models = {\n",
        "    \"densenet\": densenet,\n",
        "    \"vgg\": vgg,\n",
        "    \"mobilenet\": mobilenet,\n",
        "    \"efficientnet\": efficientnet,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TSM3enJbUHmO"
      },
      "outputs": [],
      "source": [
        "def create_patch(patch_size=(3, 3)):\n",
        "    patch = torch.randn(3, *patch_size, requires_grad=True, device=device)  # RGB\n",
        "    return patch\n",
        "\n",
        "\n",
        "def place_patch(img, patch):\n",
        "    patch = patch.to(img.device)\n",
        "    patched_img = img.clone()\n",
        "    batch_size, _, h, w = patched_img.size()\n",
        "    ph, pw = patch.size(1), patch.size(2)\n",
        "    for i in range(batch_size):\n",
        "        x_offset = torch.randint(0, h - ph + 1, (1,)).item()\n",
        "        y_offset = torch.randint(0, w - pw + 1, (1,)).item()\n",
        "        patched_img[i, :, x_offset : x_offset + ph, y_offset : y_offset + pw] = patch\n",
        "    return patched_img\n",
        "\n",
        "\n",
        "def patch_training_step(\n",
        "    model, patch, target_class=None, dataloader=None, optimizer=None, criterion=None\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        patched_images = place_patch(images, patch)  # Apply patch to images\n",
        "        outputs = model(patched_images)\n",
        "\n",
        "        if target_class is not None:\n",
        "            labels = torch.full(\n",
        "                (images.size(0),), target_class, dtype=torch.long, device=device\n",
        "            )\n",
        "            loss = criterion(outputs, labels)\n",
        "        else:\n",
        "            loss = -criterion(outputs, labels)  # reverse the loss\n",
        "\n",
        "        # loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            patch.clamp_(-1, 1)  # Ensure the patch values remain within a valid range\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "def train_adversarial_patch(\n",
        "    model, patch, dataloader=None, target_class=None, num_epochs=20, lr=0.0001\n",
        "):\n",
        "    if dataloader is None:\n",
        "        dataloader = trainloader\n",
        "\n",
        "    patch_optimizer = optim.Adam(\n",
        "        [patch], lr=lr\n",
        "    )  # Use Adam optimizer for learning rate adjustment\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for epoch in range(num_epochs):\n",
        "        loss = patch_training_step(\n",
        "            model, patch, target_class, dataloader, patch_optimizer, criterion\n",
        "        )\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Sf5i-ecFUHmO"
      },
      "outputs": [],
      "source": [
        "def evaluate_patch(model, patch, dataloader, target_class=None):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            patched_images = place_patch(images, patch)\n",
        "            outputs = model(patched_images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            if target_class is not None:\n",
        "                correct += (predicted == target_class).sum().item()\n",
        "            else:\n",
        "                correct += (\n",
        "                    (predicted != labels).sum().item()\n",
        "                )  # Evaluate untargeted attack\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    if target_class is not None:\n",
        "        print(f\"Targeted Attack Success Rate (Class {target_class}): {accuracy:.2f}%\")\n",
        "    else:\n",
        "        print(f\"Untargeted Attack Success Rate: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_9TbLW7IUHmP"
      },
      "outputs": [],
      "source": [
        "target_classes = [0, 1, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZxKK39dXUHmP"
      },
      "outputs": [],
      "source": [
        "class_names = {\n",
        "    0: \"airplane\",\n",
        "    1: \"automobile\",\n",
        "    2: \"bird\",\n",
        "    3: \"cat\",\n",
        "    4: \"deer\",\n",
        "    5: \"dog\",\n",
        "    6: \"frog\",\n",
        "    7: \"horse\",\n",
        "    8: \"ship\",\n",
        "    9: \"truck\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "L2hioA_yUHmP"
      },
      "outputs": [],
      "source": [
        "def denormalize(tensor, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)):\n",
        "    \"\"\"\n",
        "    Denormalize a tensor image.\n",
        "\n",
        "    Args:\n",
        "        tensor (torch.Tensor): Normalized image tensor.\n",
        "        mean (tuple): Mean used for normalization.\n",
        "        std (tuple): Standard deviation used for normalization.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Denormalized image tensor.\n",
        "    \"\"\"\n",
        "    for t, m, s in zip(tensor, mean, std):\n",
        "        t.mul_(s).add_(m)\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def visualize_misclassified_patched_images(\n",
        "    model, patch, dataloader, target_class=None, num_images=5\n",
        "):\n",
        "    \"\"\"\n",
        "    Visualize misclassified images after applying the adversarial patch.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Trained CIFAR-10 classifier.\n",
        "        patch (torch.Tensor): Trained adversarial patch.\n",
        "        dataloader (DataLoader): DataLoader for evaluation data.\n",
        "        target_class (int, optional): Target class for targeted attacks. Defaults to None for untargeted attacks.\n",
        "        num_images (int, optional): Number of misclassified images to visualize. Defaults to 5.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    misclassified = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            patched_images = place_patch(images, patch)\n",
        "            outputs = model(patched_images)\n",
        "            _, predicted = outputs.max(1)\n",
        "\n",
        "            if target_class is not None:\n",
        "                # Only include images not originally of target_class but predicted as target_class\n",
        "                mask = (predicted == target_class) & (labels != target_class)\n",
        "            else:\n",
        "                # Untargeted Attack: Any prediction that doesn't match the true label\n",
        "                mask = predicted != labels\n",
        "\n",
        "            for i in range(images.size(0)):\n",
        "                if mask[i]:\n",
        "                    misclassified.append(\n",
        "                        (\n",
        "                            images[i].cpu(),\n",
        "                            patched_images[i].cpu(),\n",
        "                            labels[i].cpu(),\n",
        "                            predicted[i].cpu(),\n",
        "                        )\n",
        "                    )\n",
        "                if len(misclassified) >= num_images:\n",
        "                    break\n",
        "            if len(misclassified) >= num_images:\n",
        "                break\n",
        "\n",
        "    if not misclassified:\n",
        "        print(\"No misclassified images found with the current patch.\")\n",
        "        return\n",
        "\n",
        "    # Plotting\n",
        "    for idx, (orig, patched, true_label, pred_label) in enumerate(misclassified):\n",
        "        orig = denormalize(orig).permute(1, 2, 0).numpy()\n",
        "        patched = denormalize(patched).permute(1, 2, 0).numpy()\n",
        "\n",
        "        orig = np.clip(orig, 0, 1)\n",
        "        patched = np.clip(patched, 0, 1)\n",
        "\n",
        "        plt.figure(figsize=(4, 2))\n",
        "\n",
        "        # Original Image\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(orig)\n",
        "        plt.title(f\"Original\\nTrue: {class_names[true_label.item()]}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        # Patched Image\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(patched)\n",
        "        plt.title(f\"Patched\\nPredicted: {class_names[pred_label.item()]}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAB6CFUwUHmP",
        "outputId": "259ef864-1f07-47d4-87b5-e463ce2a007a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Class: airplane\n",
            "Patch Size: (3, 3)\n",
            "Transfer to Model: densenet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-d9ece936750f>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  patch = torch.load(patch_filename).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targeted Attack Success Rate (Class 0): 14.12%\n",
            "Transfer to Model: vgg\n",
            "Targeted Attack Success Rate (Class 0): 30.63%\n",
            "Transfer to Model: mobilenet\n",
            "Targeted Attack Success Rate (Class 0): 12.44%\n",
            "Transfer to Model: efficientnet\n",
            "Targeted Attack Success Rate (Class 0): 10.26%\n",
            "Patch Size: (5, 5)\n",
            "Transfer to Model: densenet\n",
            "Targeted Attack Success Rate (Class 0): 9.85%\n",
            "Transfer to Model: vgg\n",
            "Targeted Attack Success Rate (Class 0): 36.81%\n",
            "Transfer to Model: mobilenet\n",
            "Targeted Attack Success Rate (Class 0): 14.28%\n",
            "Transfer to Model: efficientnet\n",
            "Targeted Attack Success Rate (Class 0): 10.00%\n",
            "Patch Size: (7, 7)\n",
            "Transfer to Model: densenet\n",
            "Targeted Attack Success Rate (Class 0): 17.74%\n",
            "Transfer to Model: vgg\n",
            "Targeted Attack Success Rate (Class 0): 45.39%\n",
            "Transfer to Model: mobilenet\n",
            "Targeted Attack Success Rate (Class 0): 23.30%\n",
            "Transfer to Model: efficientnet\n",
            "Targeted Attack Success Rate (Class 0): 18.51%\n",
            "Patch Size: (16, 16)\n",
            "Transfer to Model: densenet\n",
            "Targeted Attack Success Rate (Class 0): 6.68%\n",
            "Transfer to Model: vgg\n",
            "Targeted Attack Success Rate (Class 0): 0.00%\n",
            "Transfer to Model: mobilenet\n",
            "Targeted Attack Success Rate (Class 0): 95.10%\n",
            "Transfer to Model: efficientnet\n",
            "Targeted Attack Success Rate (Class 0): 3.28%\n",
            "Target Class: automobile\n",
            "Patch Size: (3, 3)\n",
            "Transfer to Model: densenet\n",
            "Targeted Attack Success Rate (Class 1): 8.90%\n",
            "Transfer to Model: vgg\n",
            "Targeted Attack Success Rate (Class 1): 5.97%\n",
            "Transfer to Model: mobilenet\n",
            "Targeted Attack Success Rate (Class 1): 12.90%\n",
            "Transfer to Model: efficientnet\n",
            "Targeted Attack Success Rate (Class 1): 9.95%\n",
            "Patch Size: (5, 5)\n",
            "Transfer to Model: densenet\n",
            "Targeted Attack Success Rate (Class 1): 10.14%\n",
            "Transfer to Model: vgg\n",
            "Targeted Attack Success Rate (Class 1): 10.99%\n",
            "Transfer to Model: mobilenet\n",
            "Targeted Attack Success Rate (Class 1): 14.54%\n",
            "Transfer to Model: efficientnet\n",
            "Targeted Attack Success Rate (Class 1): 8.99%\n",
            "Patch Size: (7, 7)\n",
            "Transfer to Model: densenet\n",
            "Targeted Attack Success Rate (Class 1): 12.99%\n",
            "Transfer to Model: vgg\n",
            "Targeted Attack Success Rate (Class 1): 9.63%\n",
            "Transfer to Model: mobilenet\n",
            "Targeted Attack Success Rate (Class 1): 14.52%\n",
            "Transfer to Model: efficientnet\n",
            "Targeted Attack Success Rate (Class 1): 8.16%\n",
            "Patch Size: (16, 16)\n",
            "Transfer to Model: densenet\n",
            "Targeted Attack Success Rate (Class 1): 39.19%\n",
            "Transfer to Model: vgg\n",
            "Targeted Attack Success Rate (Class 1): 49.32%\n",
            "Transfer to Model: mobilenet\n",
            "Targeted Attack Success Rate (Class 1): 11.41%\n",
            "Transfer to Model: efficientnet\n",
            "Targeted Attack Success Rate (Class 1): 2.26%\n",
            "Target Class: bird\n",
            "Patch Size: (3, 3)\n",
            "Transfer to Model: densenet\n",
            "Targeted Attack Success Rate (Class 2): 31.64%\n",
            "Transfer to Model: vgg\n",
            "Targeted Attack Success Rate (Class 2): 41.94%\n",
            "Transfer to Model: mobilenet\n",
            "Targeted Attack Success Rate (Class 2): 13.83%\n",
            "Transfer to Model: efficientnet\n",
            "Targeted Attack Success Rate (Class 2): 13.75%\n",
            "Patch Size: (5, 5)\n",
            "Transfer to Model: densenet\n",
            "Targeted Attack Success Rate (Class 2): 60.79%\n",
            "Transfer to Model: vgg\n",
            "Targeted Attack Success Rate (Class 2): 29.29%\n",
            "Transfer to Model: mobilenet\n",
            "Targeted Attack Success Rate (Class 2): 41.64%\n",
            "Transfer to Model: efficientnet\n",
            "Targeted Attack Success Rate (Class 2): 15.37%\n",
            "Patch Size: (7, 7)\n",
            "Transfer to Model: densenet\n",
            "Targeted Attack Success Rate (Class 2): 77.69%\n",
            "Transfer to Model: vgg\n",
            "Targeted Attack Success Rate (Class 2): 28.99%\n",
            "Transfer to Model: mobilenet\n",
            "Targeted Attack Success Rate (Class 2): 43.61%\n",
            "Transfer to Model: efficientnet\n",
            "Targeted Attack Success Rate (Class 2): 17.39%\n",
            "Patch Size: (16, 16)\n",
            "Transfer to Model: densenet\n",
            "Targeted Attack Success Rate (Class 2): 64.19%\n",
            "Transfer to Model: vgg\n",
            "Targeted Attack Success Rate (Class 2): 1.42%\n",
            "Transfer to Model: mobilenet\n",
            "Targeted Attack Success Rate (Class 2): 7.36%\n",
            "Transfer to Model: efficientnet\n",
            "Targeted Attack Success Rate (Class 2): 27.60%\n"
          ]
        }
      ],
      "source": [
        "for target_class in target_classes:\n",
        "    print(f\"Target Class: {class_names[target_class]}\")\n",
        "\n",
        "    for patch_size in [(3, 3), (5, 5), (7, 7), (16, 16)]:\n",
        "        print(f\"Patch Size: {patch_size}\")\n",
        "\n",
        "        for model_name, model in transfer_models.items():\n",
        "            print(f\"Transfer to Model: {model_name}\")\n",
        "\n",
        "            patch_filename = f\"adversarial_patch_{class_names[target_class]}_{patch_size}_baseline.pth\"\n",
        "\n",
        "            patch = torch.load(patch_filename).to(device)\n",
        "\n",
        "            evaluate_patch(model, patch, testloader, target_class=target_class)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}