{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiBBUKRwpMyT",
        "outputId": "2e721e18-49d0-484f-ef78-3e6f7dab9ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/Deep_learning_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS9Zt475pN_d",
        "outputId": "54787ee2-14d2-4531-d1b7-2b46a8b19e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Deep_learning_final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGOPgQETpLQC"
      },
      "outputs": [],
      "source": [
        "# data_loader.py\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "def load_cifar10(batch_size=32, num_workers=2, train_val_split=0.9):\n",
        "    \"\"\"\n",
        "    Load and prepare CIFAR-10 dataset with train/validation split\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): Size of each batch\n",
        "        num_workers (int): Number of workers for data loading\n",
        "        train_val_split (float): Ratio of training data to total data\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_loader, val_loader, class_names)\n",
        "    \"\"\"\n",
        "    # CIFAR-10 normalization constants\n",
        "    NORM_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "    NORM_STD = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "    # Define transforms\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize(NORM_MEAN, NORM_STD)]\n",
        "    )\n",
        "\n",
        "    # Load dataset\n",
        "    dataset = torchvision.datasets.CIFAR10(\n",
        "        root=\"./data\", train=True, download=True, transform=transform\n",
        "    )\n",
        "\n",
        "    # Split into train and validation sets\n",
        "    train_size = int(len(dataset) * train_val_split)\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SykAKldRpLQD"
      },
      "outputs": [],
      "source": [
        "# model_loader.py\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "def load_model(model_name=\"resnet18\", pretrained=True):\n",
        "    \"\"\"\n",
        "    Load and prepare the model for adversarial attack\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name of the model architecture\n",
        "        pretrained (bool): Whether to use pretrained weights\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.Module: Prepared model\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if model_name.lower() == \"resnet18\":\n",
        "        model = models.resnet18(pretrained=pretrained)\n",
        "    elif model_name.lower() == \"resnet50\":\n",
        "        model = models.resnet50(pretrained=pretrained)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()  # Set to evaluation mode\n",
        "\n",
        "    return model, device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmdkJWVRpLQE"
      },
      "outputs": [],
      "source": [
        "# patch_generator.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class PatchGenerator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        device,\n",
        "        norm_mean=(0.4914, 0.4822, 0.4465),\n",
        "        norm_std=(0.2023, 0.1994, 0.2010),\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.norm_mean = torch.FloatTensor(norm_mean)[:, None, None].to(device)\n",
        "        self.norm_std = torch.FloatTensor(norm_std)[:, None, None].to(device)\n",
        "\n",
        "    def _normalize_patch(self, patch):\n",
        "        \"\"\"Normalize patch values to match dataset normalization\"\"\"\n",
        "        return (torch.tanh(patch) + 1 - 2 * self.norm_mean) / (2 * self.norm_std)\n",
        "\n",
        "    def place_patch(self, images, patch, random_location=True):\n",
        "        \"\"\"Apply the adversarial patch to images\"\"\"\n",
        "        patched_images = images.clone()\n",
        "        patch_h, patch_w = patch.shape[-2:]\n",
        "\n",
        "        if random_location:\n",
        "            for i in range(images.shape[0]):\n",
        "                h_offset = np.random.randint(0, images.shape[2] - patch_h - 1)\n",
        "                w_offset = np.random.randint(0, images.shape[3] - patch_w - 1)\n",
        "                patched_images[\n",
        "                    i, :, h_offset : h_offset + patch_h, w_offset : w_offset + patch_w\n",
        "                ] = self._normalize_patch(patch)\n",
        "        else:\n",
        "            # Center the patch\n",
        "            h_offset = (images.shape[2] - patch_h) // 2\n",
        "            w_offset = (images.shape[3] - patch_w) // 2\n",
        "            patched_images[\n",
        "                :, :, h_offset : h_offset + patch_h, w_offset : w_offset + patch_w\n",
        "            ] = self._normalize_patch(patch)\n",
        "\n",
        "        return patched_images\n",
        "\n",
        "    def generate_patch(\n",
        "        self, target_class, patch_size, train_loader, num_epochs=5, lr=0.1, momentum=0.8\n",
        "    ):\n",
        "        \"\"\"Generate adversarial patch\"\"\"\n",
        "        if isinstance(patch_size, int):\n",
        "            patch_size = (patch_size, patch_size)\n",
        "\n",
        "        # Initialize patch\n",
        "        patch = nn.Parameter(\n",
        "            torch.zeros(3, patch_size[0], patch_size[1], device=self.device),\n",
        "            requires_grad=True,\n",
        "        )\n",
        "\n",
        "        optimizer = optim.SGD([patch], lr=lr, momentum=momentum)\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            epoch_loss = 0.0\n",
        "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "            for images, _ in pbar:\n",
        "                images = images.to(self.device)\n",
        "                target_labels = torch.full(\n",
        "                    (images.shape[0],),\n",
        "                    target_class,\n",
        "                    device=self.device,\n",
        "                    dtype=torch.long,\n",
        "                )\n",
        "\n",
        "                patched_images = self.place_patch(images, patch)\n",
        "                predictions = self.model(patched_images)\n",
        "\n",
        "                loss = loss_fn(predictions, target_labels)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "            scheduler.step()\n",
        "            print(\n",
        "                f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {epoch_loss/len(train_loader):.4f}\"\n",
        "            )\n",
        "\n",
        "        return patch.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj6EnyCwpLQE"
      },
      "outputs": [],
      "source": [
        "# patch_tester.py\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class PatchTester:\n",
        "    def __init__(self, model, device, patch_generator):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.patch_generator = patch_generator\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def evaluate_patch(self, patch, val_loader, target_class, num_augmentations=4):\n",
        "        \"\"\"Evaluate patch effectiveness\"\"\"\n",
        "        total_success = 0\n",
        "        total_top5_success = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for images, labels in tqdm(val_loader, desc=\"Evaluating patch\"):\n",
        "            for _ in range(num_augmentations):\n",
        "                images = images.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                patched_images = self.patch_generator.place_patch(images, patch)\n",
        "                predictions = self.model(patched_images)\n",
        "\n",
        "                non_target_mask = labels != target_class\n",
        "                top1_success = torch.logical_and(\n",
        "                    predictions.argmax(dim=-1) == target_class, non_target_mask\n",
        "                )\n",
        "                top5_success = torch.logical_and(\n",
        "                    (predictions.topk(5, dim=-1)[1] == target_class).any(dim=-1),\n",
        "                    non_target_mask,\n",
        "                )\n",
        "\n",
        "                total_success += top1_success.sum().item()\n",
        "                total_top5_success += top5_success.sum().item()\n",
        "                total_samples += non_target_mask.sum().item()\n",
        "\n",
        "        return {\n",
        "            \"top1_success_rate\": total_success / total_samples,\n",
        "            \"top5_success_rate\": total_top5_success / total_samples,\n",
        "        }\n",
        "\n",
        "    def visualize_patch(self, patch, title=\"Adversarial Patch\"):\n",
        "        \"\"\"Visualize a single patch\"\"\"\n",
        "        patch_display = (torch.tanh(patch) + 1) / 2\n",
        "        patch_display = patch_display.cpu().permute(1, 2, 0).numpy()\n",
        "        patch_display = np.clip(patch_display, 0.0, 1.0)\n",
        "\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(patch_display)\n",
        "        plt.title(title)\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "    def visualize_attack(self, patch, images, labels, class_names):\n",
        "        \"\"\"Visualize patch attack on sample images\"\"\"\n",
        "        with torch.no_grad():\n",
        "            # Get original predictions\n",
        "            orig_pred = self.model(images.to(self.device))\n",
        "            orig_pred_classes = orig_pred.argmax(dim=-1)\n",
        "\n",
        "            # Apply patch and get new predictions\n",
        "            patched_images = self.patch_generator.place_patch(\n",
        "                images.to(self.device), patch\n",
        "            )\n",
        "            patch_pred = self.model(patched_images)\n",
        "            patch_pred_classes = patch_pred.argmax(dim=-1)\n",
        "\n",
        "            # Visualization\n",
        "            fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "            for i in range(4):\n",
        "                # Original image\n",
        "                axes[0, i].imshow(images[i].cpu().permute(1, 2, 0).numpy())\n",
        "                axes[0, i].set_title(f\"Original: {class_names[orig_pred_classes[i]]}\")\n",
        "                axes[0, i].axis(\"off\")\n",
        "\n",
        "                # Patched image\n",
        "                axes[1, i].imshow(patched_images[i].cpu().permute(1, 2, 0).numpy())\n",
        "                axes[1, i].set_title(f\"Patched: {class_names[patch_pred_classes[i]]}\")\n",
        "                axes[1, i].axis(\"off\")\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "PoJbio9epLQF",
        "outputId": "8fc894fb-eaec-42a7-830c-6575bcfeb637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CIFAR-10 dataset...\n",
            "Files already downloaded and verified\n",
            "Loading model...\n",
            "\n",
            "Generating patch for class: airplane\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 1407/1407 [00:47<00:00, 29.46it/s, loss=9.3829]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Average Loss: 10.2420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 1407/1407 [00:46<00:00, 30.47it/s, loss=10.6443]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5, Average Loss: 10.2109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 1407/1407 [00:45<00:00, 30.95it/s, loss=11.5071]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5, Average Loss: 10.2015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 1407/1407 [00:44<00:00, 31.43it/s, loss=10.4341]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5, Average Loss: 10.2032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 1407/1407 [00:44<00:00, 31.68it/s, loss=10.5198]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5, Average Loss: 10.2055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating patch: 100%|██████████| 157/157 [00:07<00:00, 20.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for airplane:\n",
            "Top-1 Success Rate: 0.00%\n",
            "Top-5 Success Rate: 0.00%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load data\n",
        "print(\"Loading CIFAR-10 dataset...\")\n",
        "train_loader, val_loader, class_names = load_cifar10()\n",
        "\n",
        "# Load model\n",
        "print(\"Loading model...\")\n",
        "model, device = load_model()\n",
        "\n",
        "# Initialize patch generator\n",
        "patch_generator = PatchGenerator(model, device)\n",
        "\n",
        "# Initialize patch tester\n",
        "patch_tester = PatchTester(model, device, patch_generator)\n",
        "\n",
        "# Generate patches for specific classes\n",
        "target_classes = [\"airplane\"]\n",
        "patch_size = 3  # Start with small patches\n",
        "results = {}\n",
        "\n",
        "for target_class in target_classes:\n",
        "    print(f\"\\nGenerating patch for class: {target_class}\")\n",
        "    class_idx = class_names.index(target_class)\n",
        "\n",
        "    # Generate patch\n",
        "    patch = patch_generator.generate_patch(\n",
        "        target_class=class_idx, patch_size=patch_size, train_loader=train_loader\n",
        "    )\n",
        "\n",
        "    # Evaluate patch\n",
        "    metrics = patch_tester.evaluate_patch(patch, val_loader, class_idx)\n",
        "    results[target_class] = metrics\n",
        "\n",
        "    # Visualize patch\n",
        "    print(f\"\\nResults for {target_class}:\")\n",
        "    print(f\"Top-1 Success Rate: {metrics['top1_success_rate']:.2%}\")\n",
        "    print(f\"Top-5 Success Rate: {metrics['top5_success_rate']:.2%}\")\n",
        "    patch_tester.visualize_patch(patch, f\"Adversarial Patch for {target_class}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}